## 📊 Redis 캐싱 적용 전·후 성능 비교 (k6 부하 테스트)

### 1. 테스트 목적

* **Redis 캐싱** 적용 전·후 성능 차이를 정량적으로 검증
* 대규모 요청(10,000건) 처리 시 **응답속도, 처리량, 안정성** 개선 여부 확인

### 2. 테스트 환경

* **테스트 도구**: [k6](https://k6.io/)
* **시나리오**: 10,000 iterations, 50 VUs, 동일 조건 반복 실행
* **서버 환경**: (CPU/RAM/네트워크/DB/S3 설정 명시)
* **조건**

  1. **캐싱 전 코드** – DB/S3 직접 조회
  2. **캐싱 후 최초 조회 (Cold Cache)** – 캐시 미스 상태
  3. **캐싱 후 2차 조회 (Warm Cache)** – 캐시 히트 상태

### 3. 테스트 결과

| 구분      | 평균 응답(ms) | p95(ms) | 최대 응답(ms) | 처리량(req/s) | 드롭 요청 수 | 비고                 |
| ------- | --------- | ------- | --------- | ---------- | ------- | ------------------ |
| 캐싱 전    | 11,290    | 15,620  | 30,600    | 4.30       | 6,079   | 테스트 미완료, 대규모 드롭 발생 |
| 캐싱 후 최초 | 207.85    | 201.57  | 14,340    | 108.70     | 0       | 일부 outlier 존재      |
| 캐싱 후 2차 | 59.59     | 89.3    | 398       | 160.69     | 0       | 안정적, 롱테일 제거        |

### 4. 개선 효과

* **평균 응답시간**: 11.29s → 59.59ms (**약 189배 개선**)
* **p95 응답시간**: 15.62s → 89.3ms (**약 175배 개선**)
* **최대 응답시간**: 30.6s → 398ms (**약 77배 개선**)
* **처리량**: 4.30 → 160.69 req/s (**약 37배 증가**)
* **드롭 요청**: 6,079건 → 0건 (**안정성 확보**)

### 5. 결론

* Redis 캐싱 적용만으로도 **Cold Cache 상태에서 수십 배 성능 향상**
* Warm Cache 상태에서는 **롱테일 제거 + 처리량 증가**로 안정적 운영 가능
* 대규모 트래픽 환경에서 실서비스 대응 가능 수준 확보